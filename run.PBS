#!/bin/bash
#SBATCH --account punim0980
#SBATCH --partition gpu-a100-short

#SBATCH --gres=gpu:1
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=112G
#SBATCH --time=4:00:00
#SBATCH --output CUB_PIPNet.out
#SBATCH --open-mode=truncate
#SBATCH --job-name=CUB_PIPNet
#SBATCH --mail-type=ALL
#SBATCH --mail-user=nathaniel.bloomfield@unimelb.edu.au

export mysystem=spartan
export env_seed=1
export HYDRA_FULL_ERROR=1
export TORCH_HOME=/data/cephfs/punim0980/torch_hub
export TRANSFORMERS_CACHE=/data/cephfs/punim0980/torch_hub
export HUGGINGFACE_HUB_CACHE=/data/cephfs/punim0980/torch_hub/hub
export LIGHTLY_DID_VERSION_CHECK=True

module load Python/3.10.4
module load CUDA/11.7.0
source /data/cephfs/punim0980/venvs/mysemiv4/bin/activate

cd /data/cephfs/punim0980/tests/PIPNet/

python main.py --dataset CUB-200-2011 --validation_size 0.0 --net convnext_tiny_26 --batch_size 64 --batch_size_pretrain 128 --epochs 60 --optimizer Adam --lr 0.05 --lr_block 0.0005 --lr_net 0.0005 --weight_decay 0.0  --log_dir './runs/pipnet_cub_cnext26' --num_features 0 --image_size 224 --state_dict_dir_net '' --freeze_epochs 10 --dir_for_saving_images 'Visualization_results'  --epochs_pretrain 10 --seed 1 --gpu_ids '' --num_workers 8 

##Log this job's resource usage stats###
my-job-stats -a -n -s
##
  